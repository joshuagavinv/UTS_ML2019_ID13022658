{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "A1_Report13022658Critique.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuagavinv/UTS_ML2019_ID13022658/blob/master/A1_Report13022658Critique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbQtNQ42dcBN",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN_msqRPdcBO",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "<p style='text-align: justify;'> Up until now, Face Recognition has been a hot topic in the field of  AI and Computer vision. Features such as face biometrics (Face ID),  traffic surveillance , and taxonomic observation are one of the many examples of its application (Belhumeur, Hespanha  & Kriegman, D.J. 1997).  Unfortunately, there’s many roadblocks involving this pattern recognition, particularly in multiple variation of illumination and expression each person can have. \n",
        " \n",
        "\n",
        "\n",
        "\n",
        " In this report, we will look at a journal article published in IEEE Transactions on Pattern Analysis and Machine Intelligence titled ‘‘Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection’. The scientific paper tried to describe 4 appearance based method of image recognition while comparing their performance in variability of light, and facial expression except variation in pose (Belhumeur, Hespanha  & Kriegman, D.J. 1997). Furthermore,  the authors continued their experiment in differentiating people with glasses or not.\n",
        "\n",
        "\n",
        "In this critique report, we will go through the content of the article, innovation and technical aspect from their experiments. Lastly, we will elaborate more on the application and X-factor of the techniques, and evaluate the overall presentation of the paper itself. </p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5WlwC6ydcBQ",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1ZTK6SldcBQ",
        "colab_type": "text"
      },
      "source": [
        "<p style='text-align: justify;'>The paper,  presents four face recognition methods that handle illumination & facial expression. The authors further explain and compare the methods in detail, highlighting its processes, pro & cons,  comparing the algorithm using Harvard and Yale database methods.\n",
        "\n",
        "  The first two methods are well-known for pattern recognition. Correlation is said to be one of the simplest solution where the model  only need to choose the faces in the training set that best correspond with the test one after normalisation. The normalisation pre-processing aims to filter out the effect of light variation. (Belhumeur, Hespanha  & Kriegman, D.J. 1997). Despite of its simplicity, it is computationally expensive and requires a numerous amount of  photos for each person under different lighting. Eigenfaces techniques overcome this issues by approaching dimensionality reduction scheme using Principal Component Analysis (Belhumeur, Hespanha  & Kriegman, D.J. 1997).  In practice, image dimension are too large which is why PCA is implemented to map a new eigenfaces that represent the maximum variance in correlation, reducing the number of features needed (Martinez & Kak 2001), however this method also maximise within-class scatter, thus misclassification is high (Belhumeur, Hespanha  & Kriegman, D.J. 1997). It’s also have been said that the effect of variation in light will be reduced by discarding the first three eigenvectors which will be experimented by the authors later on.  \n",
        "\n",
        "The next two methods are developed by the authors based on Lambertian surface and Fisherfaces. The linear subspaces method points out that if  three images taken under the same point of view, with linearly independent light direction a 3D linear subspace can be generated, allowing classification insensitive to light by comparing it’s distances. Unfortunately, Lambertian surface, assumes that it is equally bright in all direction and since faces do produce self-shadowing, the subspace will deviate (Basri  & Jacobs 2003). The final method Fisherface uses a dimensionality reduction approach similar to Eigenface, while preserving linear separability between class.\n",
        "\n",
        "    \n",
        "The method maximises  between class scatter matrix while minimizing the within class one, as can be seen from the FLD vs PCA figure shown in the article, PCA mix the class together, while FLD, cluster the same classes in different region (Belhumeur, Hespanha  & Kriegman, D.J. 1997). To avoid the complication of singular issues, the authors (1997) suggests to project the image to a lower dimensional space using PCA and then applying the standard FLD for optimal separation.\n",
        "\n",
        "To compare the performance of this techniques, the authors did an experiment using for variation in light and both facial & light. The experiments use different subsets (5 for variation in light, 4 for both light,  facial & eye wear). The second experiment also compare the model performance in ‘full face’ & ‘closely cropped’ as well as implementing a leaving one out strategy, to identify which image was filtered out from the datasets (Belhumeur, Hespanha  & Kriegman, D.J. 1997). The authors further  shows graph illustrating the error rates of each models, along with information regarding the reduced space, along with detail results from the article figure 8 & 9. \n",
        "    \n",
        "    \n",
        " Overall, the results shows that all the algorithms perform well under good lighting condition, with notes that Eigenface do well in more reduced space. However, the classifier performance gradually decline as light is move off from axis, with exception to Linear Subspace & Eigenface at around 0 to 1 % error rate.  Aside from that, it seems that removing the first three components for Eigenface method improve its performance. Despite of the great performance of the proposed methods, the facial variation in second experiment, greatly reduce the accuracy of Linear Subspace, due to deviation in the face, however, Fisherface still perform well with 7.3% and 0.6% for both for crop and full face respectively. Furthermore, it has been confirmed that the algorithm works better with full-face compared with crop ones. Next, the authors continue its experiments in glasses recognition with 36 people in the Yale datasets both wearing glass and not with equal proportion. The result was that PCA has around 10 times error rate compared to Fisherface. The authors concludes that Fisherface seems to be the best method at handling light and facial expression, while Linear subspace deteriorate to facial expression.\n",
        "</p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKbosCkfdcBR",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxw5ii8ldcBS",
        "colab_type": "text"
      },
      "source": [
        "This section will discuss the innovation of the journal article. First, it will cover the aim of the paper. Second,  we will go through the innovation and novelty that the paper have made. Finally, the contribution of the paper for future research will be examined. The Journal Article aim to highlight and solve the issues of light and facial variation in face recognition. As previously mentioned, the authors introduced, Linear Sub space and Fisherface for solving this recognition. \n",
        "\n",
        "LDA that was actually invented by Fisherface in 1936, and was designed for two class problem specifically taxonomic are now repurposed by the authors to accommodate for multiple class especially since each person in the training sets it’s a class of its own (Fratric & Ribaric 2011, Belhumeur, Hespanha  & Kriegman, D.J. 1997 ). Overall it can be said that the alternative method, is innovative as its extend the  algorithm’s application of both Fisher and Lambertian Theory. \n",
        "\n",
        "Although the paper is published in 1997, this research paper is still relevant, and have become a good solid foundation, enabling  modern face recognition algorithm to be born. For instance, Basri  & Jacobs 2003 introduced a Lambertian reflectance function that could handle the deviation in the linear subspace by implementing a low pass filter. Numerous variation of Fisher LDA have been developed such as GA Fisher, where it solve the small dataset problem, and experienced around 5% increase in performance (Zheng, Lai & Yuen  2005). Furthermore, the specific class LDA also open opportunities for face recognition based on features such as glasses, which can be further expanded to nationality, hair type, depending on the desired category. Aside from that, the algorithm proposed here, haven’t been tested to handle variation in pose but it can be expanded to that objective (Belhumeur, Hespanha  & Kriegman, D.J. 1997). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSE23-BvdcBS",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRaUG1p9dcBT",
        "colab_type": "text"
      },
      "source": [
        "The quality assessment here will revolve around the main stages of Face recognition System issued by Tripathi, Singh  & Arora 2009, specifically in its datasets, pre-processing & feature extraction, Classifiers & performance evaluation.\n",
        "\n",
        "Firstly, the database use in this experiment is from Harvard Robotics Laboratory containing different variation of systematic illumination and the author’s own constructed database from Yale with facial and light variation. Harvard and Yale is a very reputable university, however, it would be more reliable if they use FERET database, which is the standard for face recognition research (Phillips et al 1998). Furthermore, it has been inferred that PCA might outperform Fisher LDA when the training set is too small or nonuniformly sample the population distribution Martinez & Kak 2001), which should be further explored. Next, the authors briefly describe the theory and the process of each method in a comprehensible way, for instance normalizing mean and variance (Belhumeur, Hespanha  & Kriegman, D.J. 1997), however in order to replicate the research, it would be preferable if the authors could highlight the process / code, specifically in its pre-processing and feature extraction  in the appendix section. Aside from that,  Yang (2002) manage to develop a kernel fisher with reference to this paper, improving the techniques. Classifiers used in the experiment is nearest neighbour, which classify the membership based on its surrounding neighbours. Although, the comparison of the experiments based on the error rates of the subset / test set seem to produce a reliable result, it would be interesting to see other classifier such as SVM, since it has been researched by Cortes  & Vapnik (1995) that SVM is overall superior to Nearest neighbour in identifying pattern, to examine its influence or consistency on the result.  The performance evaluation are measured by ranking it’s error rates on the test set, which is quite reliable, however adding a ROC curve to determine the false positive will be more informative.\n",
        "      \n",
        " Overall, the experiments was conducted well, with controlled variables and achieve the aim in developing method  independent of light and facial variation with consistent result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3erJjOPZdcBU",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPkk-6xWdcBU",
        "colab_type": "text"
      },
      "source": [
        "The proposed techniques describe in this article, clearly is appropriate for face recognition as it has been proven from numerous experiments from the authors and Yang (2002) that fisherface and Linear subspace generally perform well. The face recognition solution that focus on handling light and facial expression can be further expanded, to variability in pose as mentioned by the authors using  multiple-view representation, view-based Eigenspace or Mu- rase and Nayar’s appearance manifolds (Belhumeur, Hespanha  & Kriegman, D.J. 1997). Aside from face recognition the author also shows that the methods can be implemented in feature recognition too, such as glass classification. This open up a whole new opportunities as race, biometrics, object, diseases detection,  can be explored as the process are quite similar as shown in.\n",
        "\n",
        "For further development of the research work, following from the technical quality section, I would suggests to experiments with a lot of recognized database such as FERET, using other emerging classifiers for comparison such as SVM, neural networks, to evaluate their relevance in face recognition. Furthermore, I feel that until now, there’s still a lot of things that we didn’t know about computer vision and face recognition, as such it will be a really good debates in class. For instance, it would be very interesting to see a comparison between Eigenfaces and Fisherfaces as of why Eigenfaces can overtake fisherface as well as the reason why the first three components seems to be the variance of light, is lower eigenfaces / eigenvector important?. The authors (1997) also at the time building models for representing images in all possible illumination condition, including severe lights. Aside from that, numerous development to Fisherface and Linear subspace in Lambertian Reflectance function have been developed, which is more reason to compare the two methods as both are illustrated to be the superior algorithm in this article (Belhumeur, Hespanha  & Kriegman, D.J. 1997).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guIvhZhOdcBV",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbvNxqrGdcBV",
        "colab_type": "text"
      },
      "source": [
        "In this section, the evaluation will be done according to each heading of the journal article.\n",
        "\n",
        "\n",
        "*   **Abstract** \n",
        "\n",
        "> The abstracts provide a clear and concise summaries  regarding the background and the aim of the article, brief description of the methods,  highlighting key findings/result of the  experiments\n",
        "\n",
        "\n",
        "*   **Introduction**\n",
        "\n",
        "\n",
        ">The introduction describes the background of image recognition and method clearly as well as stating the scope of the proposed solution, that it haven’t been tested for variation in pose, but can be further expanded and briefly. It explain the report structure/flow clearly and state the experiment assumption.\n",
        "\n",
        "\n",
        "*   **Methods**\n",
        "\n",
        "\n",
        "> Overall, the section is clearly structured and briefly explained highlighting its process, pro & cons. The paper is well suited for beginners with Mathematics /Data \tScience background, however perhaps it would be beneficial to make a glossary term for interpreting certain terminology so that the arguments can be follow easily.  \n",
        "\n",
        "\n",
        "*   **Experiments**\n",
        "\n",
        "\n",
        "\n",
        "> The experiments is well structured, and clearly separated by the variability factors, and relevant visual graph with appropriate explanation and experiment assumption. However, it can be better if the whole process can be described in more details such as, so that the reader can replicate the findings\n",
        "\n",
        "\n",
        "*   **Conclusions**\n",
        "\n",
        "\n",
        "\n",
        "> Thorough concise explanation of the main findings along with future research and argumentative questions by the authors.\n",
        "\n",
        "\n",
        "*   **References**\n",
        "\n",
        "\n",
        "> The format of the references follows an official style of academic paper, complete with the authors information showing their qualification and experience, giving more confidence in the article reliability.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8XnpxyzdcBW",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "Basri, R. & Jacobs, D.W.2003, ‘Lambertian Reflectance and Linear Subspaces’, *IEEE Transactions on Pattern Analysis and  Machine Intelligence*, vol.25, no.2, pp. 218-232.\n",
        "\n",
        "Belhumeur, P.N.,  Hespanha, J.P. & Kriegman, D.J. 1997, ‘Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection’, *IEEE Transactions on Pattern Analysis and Machine Intelligence*, vol.19, no.7, pp. 711-720.\n",
        "\n",
        "Cortes, C. & Vapnik, V. 1995, ‘Support-Vector Networks’, *Machine Learning*, vol.20, pp. 273-297.\n",
        "\n",
        "Fratric, I. and Ribaric, S. (2011). ‘Local Binary LDA for Face Recognition’. *Lecture Notes in Computer Science*, pp.144-155.\n",
        "Martinez, A. & Kak, A.2001, ‘PCA versus LDA’, *IEEE Transactions on Pattern Analysis and Machine Intelligence*, vol.26, no.2, pp.257-261.\n",
        "\n",
        "Philips, P.J. et al. 1998, ‘The FERET database and evaluating procedure for face recognition algorithms’, *Empirical Evaluation Techniques in Computer Vision*, vol. 5, no. 16, pp. 295-306 \n",
        "\n",
        "Tripathi, S., Singh, L. & Arora, H.2009, ‘Face Recognition Machine Vision System Using Eigenfaces’, *International Journal of Recent Trends in Engineering*, vol.2, no.2, pp. 1-3.\n",
        "\n",
        "Yang, M.H.2002, ‘Kernel Eigenfaces vs Kernel Fisherfaces: Faces Recognition using Kernel Method’, *Fifth IEEE International Conference on Automatic Face and Gesture Recognition*, pp. 215-220.\n",
        "\n",
        "Zheng, W.S, Lai, J.H. & Yuen, P.C. 2005, ‘GA-Fisher: A New LDA-Based Face Recognition Algorithm With Selection of Principal Components’, *IEEE Transactions on Systems, Man, and Cybernetics—Part B: Cybernetics*, vol. 35, no.5, pp.1065-1078.\n",
        "\n"
      ]
    }
  ]
}